{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用 json 拆解法 - 蘋果日報關鍵字查詢為例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tw.appledaily.com/search/ajaxresult?sort=time&searchType=all&dateStart=2018%2F07%2F01&dateEnd=2018%2F07%2F25&querystrS=%E8%94%A1%E8%8B%B1%E6%96%87, page=1\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#65001\n",
    "import urllib.request\n",
    "import json\n",
    "import codecs\n",
    "import sys\n",
    "import argparse as ap\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import random\n",
    "import lxml.html\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote\n",
    "\n",
    "#python main.py 八仙塵爆 2015-06-27 2015-08-24 1\n",
    "#def argParse():\n",
    "#    parser=ap.ArgumentParser(description='Apple Daily News Crawler')\n",
    "#    parser.add_argument(\"keyword\", help=\"Serch Keyword\")\n",
    "#    parser.add_argument(\"start_date\", help=\"Start (2017-01-01)\")\n",
    "#    parser.add_argument(\"end_date\", help=\"End (2017-02-02)\" )\n",
    "#    parser.add_argument(\"pages\", help=\"Pages\")\n",
    "#    return parser.parse_args()\n",
    "\n",
    "#args=argParse()\n",
    "#keyword = args.keyword\n",
    "#start_date = args.start_date\n",
    "#end_date = args.end_date\n",
    "#pages = args.pages\n",
    "\n",
    "keyword = '蔡英文'\n",
    "start_date = '2018-07-01'\n",
    "end_date = '2018-07-25'\n",
    "pages = '1'\n",
    "\n",
    "rs = requests.session()\n",
    "\n",
    "def start_requests(uri):\n",
    "    if( len(start_date.split(\"-\"))==3 and len(end_date.split(\"-\"))==3) :\n",
    "        for i in range(1,int(pages)+1):\n",
    "            str_page = ''+('%s' % i)\n",
    "            str_rand = str(random.randint(1,99999))\n",
    "            print (uri+\", page=\"+str_page)\n",
    "            parseAppleDailyNews(uri+\"&page=\"+str_page)\n",
    "            time.sleep(0.5)\n",
    "      \n",
    "    else:\n",
    "        print (\"Data format error.\")\n",
    "\n",
    "\n",
    "def request_uri(uri):\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0'}\n",
    "    res = rs.get(uri, headers=header)\n",
    "    html_data =  res.text\n",
    "    return html_data\n",
    "\n",
    "                        \n",
    "def request_uri_content(uri):\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0'}\n",
    "    res = rs.get(uri, headers=header)\n",
    "    html_data =  res.text\n",
    "    return html_data\n",
    "\n",
    "def parseAppleDailyNews(uri):\n",
    "    # https://tw.appledaily.com/search/result?sort=time&searchType=all&dateStart=2018/07/01&dateEnd=2018/07/19&querystrS=川普&page=2\n",
    "    html_data =  request_uri(uri)\n",
    "    json_data = json.loads(html_data)\n",
    "    postdate = []\n",
    "    link = []\n",
    "    title = []\n",
    "    body = []\n",
    "    for x in json_data:\n",
    "        #print(x['title'])\n",
    "        #print(x['sharing']['url'])\n",
    "        #print(x['pubDate'])\n",
    "        strTitle = x['title']\n",
    "        strUrl = x['sharing']['url']\n",
    "        strDate = x['pubDate']\n",
    "        strBody = x['description']\n",
    "        title.append(strTitle)\n",
    "        link.append(strUrl)\n",
    "        body.append(strBody)\n",
    "        postdate.append(strDate)\n",
    "        \n",
    "    current = 0\n",
    "    while current < len(postdate):\n",
    "        items.append({\n",
    "          \"title\": title[current],\n",
    "          \"link\":link[current],\n",
    "          \"body\":body[current],\n",
    "          \"postdate\":postdate[current],\n",
    "          #\"updatetime\":datetime.datetime.now(),  # MongoDB\n",
    "          \"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "        })\n",
    "        current+=1\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #uri = 'https://tw.appledaily.com/search/result?sort=time&searchType=all&dateStart='+start_date.replace('-','%2F')+'&dateEnd='+end_date.replace('-','%2F')+'&querystrS='+quote(keyword)\n",
    "    uri = 'https://tw.appledaily.com/search/ajaxresult?sort=time&searchType=all&dateStart='+start_date.replace('-','%2F')+'&dateEnd='+end_date.replace('-','%2F')+'&querystrS='+quote(keyword)\n",
    "    items = []\n",
    "    start_requests(uri);\n",
    "    row_json = json.dumps(items, ensure_ascii=False)\n",
    "    file = codecs.open(urllib.parse.unquote(keyword)+'.json', 'w', encoding='utf-8')\n",
    "    file.write(row_json)\n",
    "    file.close()\n",
    "    r = requests.get(url=uri, headers={'Connection':'close'})\n",
    "\n",
    "#     print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
