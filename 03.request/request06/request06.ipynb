{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用 requests 搭 xpath 拆解法 - 自由時報關鍵字查詢為例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.ltn.com.tw/search?keyword=%E5%B7%9D%E6%99%AE&conditions=and&start_time=2018-10-20&end_time=2018-10-25&page=1\n",
      "防堵非法移民大軍 美軍擬進駐美墨邊境\n",
      "https://news.ltn.com.tw/news/world/breakingnews/2592412\n",
      "美國9月貿易逆差再創新高 連續4個月擴大\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2592342\n",
      "美中貿易戰衝擊亞洲  這國有望替代中國市場\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2592064\n",
      "安習會登場 外媒： 川普 貿易戰正使日中關係解凍\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2592213\n",
      "豬隊友？韓國瑜粉絲合成習近平「合照」 又引網友熱議\n",
      "https://news.ltn.com.tw/news/politics/breakingnews/2592210\n",
      "炸彈包裹又一件！奧斯卡影帝勞勃狄尼洛也收到\n",
      "https://news.ltn.com.tw/news/world/breakingnews/2592235\n",
      "傳 川普 iPhone遭竊聽 中外交部建議「可改用華為」\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2591959\n",
      "全球股市為何陷「獵殺10月」？ 這7大原因釀災\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2591868\n",
      "哈紹吉案波及 傳美國正極力搶救沙國軍售大單\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2591744\n",
      "橋水：美歐經濟週期接近尾聲 投資人該「向東看」\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2591723\n",
      "美要退中程飛彈條約   普廷放話：歐洲誰配合將成攻擊目標\n",
      "https://news.ltn.com.tw/news/world/breakingnews/2591722\n",
      "美股續跌怪Fed？分析師：投資人更擔心貿易戰\n",
      "https://news.ltn.com.tw/news/business/breakingnews/2591719\n",
      "美中關係日趨緊張...  美前駐歐陸軍司令：15年內恐發生戰爭\n",
      "https://news.ltn.com.tw/news/world/breakingnews/2591662\n",
      "社會主義帶來破壞和失敗 白宮：應丟入歷史的垃圾桶\n",
      "https://news.ltn.com.tw/news/world/breakingnews/2591355\n",
      "川普 愛用手機私聊   美媒爆：談話全遭中俄間諜竊聽！\n",
      "https://news.ltn.com.tw/news/world/breakingnews/2591337\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#65001\n",
    "import urllib.request\n",
    "import requests\n",
    "import json\n",
    "import codecs\n",
    "import sys\n",
    "import argparse as ap\n",
    "import time\n",
    "import datetime\n",
    "from urllib.parse import quote\n",
    "from lxml import etree\n",
    "\n",
    "#python main.py 八仙塵爆 2015-06-27 2015-08-24 1\n",
    "#def argParse():\n",
    "#    parser=ap.ArgumentParser(description='Liberty Time Net Crawler')\n",
    "#    parser.add_argument(\"keyword\", help=\"Serch Keyword\")\n",
    "#    parser.add_argument(\"start_date\", help=\"Start (2017-01-01)\")\n",
    "#    parser.add_argument(\"end_date\", help=\"End (2017-02-02)\" )\n",
    "#    parser.add_argument(\"pages\", help=\"Pages\")\n",
    "#    return parser.parse_args()\n",
    "\n",
    "#args=argParse()\n",
    "#keyword = args.keyword\n",
    "#start_date = args.start_date\n",
    "#end_date = args.end_date\n",
    "#pages = args.pages\n",
    "\n",
    "\n",
    "keyword = '川普'\n",
    "start_date = '2018-10-20'\n",
    "end_date = '2018-10-25'\n",
    "pages = '1'\n",
    "\n",
    "rs = requests.session()\n",
    "\n",
    "def start_requests():\n",
    "    if( len(start_date.split(\"-\"))==3 and len(end_date.split(\"-\"))==3) :\n",
    "        SYear = start_date.split(\"-\")[0]\n",
    "        SMonth = start_date.split(\"-\")[1]\n",
    "        SDay = start_date.split(\"-\")[2]\n",
    "        EYear = end_date.split(\"-\")[0]\n",
    "        EMonth = end_date.split(\"-\")[1]\n",
    "        EDay = end_date.split(\"-\")[2]\n",
    "        urls = []\n",
    "        for i in range(1,int(pages)+1):\n",
    "            str_idx = ''+('%s' % i)\n",
    "            api = \"https://news.ltn.com.tw/search?keyword={}&conditions=and&start_time={}&end_time={}&page={}\".format(quote(keyword), start_date, end_date, str_idx)\n",
    "            urls.append(api)\n",
    "\n",
    "        for url in urls:\n",
    "            print (url)\n",
    "            parseLtnNews(url)\n",
    "            time.sleep(0.2) #間隔時間\n",
    "    else:\n",
    "        print (\"Data format error.\")\n",
    "\n",
    "\n",
    "def request_uri(uri):\n",
    "    header = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:51.0)'}\n",
    "    res = rs.get(uri, headers=header)\n",
    "    html_data =  res.text\n",
    "    return html_data\n",
    "\n",
    "\n",
    "def parseLtnNews(uri):\n",
    "    title = []\n",
    "    link = []\n",
    "    body = []\n",
    "    postdate = []\n",
    "    html_data =  request_uri(uri)\n",
    "    selector = etree.HTML(html_data)\n",
    "    newslist = selector.xpath('//*[@class=\"searchlist boxTitle\"]/li')\n",
    "    \n",
    "    for i in range(len(newslist)):\n",
    "        strTitle = ''\n",
    "        strUrl = ''\n",
    "        strBody = ''\n",
    "        strDate = ''\n",
    "        str_idx = str(i+1)\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/a//text()'\n",
    "        titleList = selector.xpath(str_xpath)\n",
    "        strTitle = \" \".join(titleList)\n",
    "        print(strTitle)\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/a//@href'\n",
    "        urlList = selector.xpath(str_xpath)[0]\n",
    "        strUrl = ''.join(urlList)\n",
    "        strUrl = strUrl\n",
    "        print(strUrl)\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/p//text()'\n",
    "        bodyList = selector.xpath(str_xpath)\n",
    "        strBody = ''.join(bodyList).replace('\\n','')\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/span//text()'\n",
    "        dateList = selector.xpath(str_xpath)\n",
    "        strDate = ''.join(dateList).replace(\"&nbsp;\",\"\")[:10]\n",
    "        if len(strTitle)>1:\n",
    "            items.append({\n",
    "                \"title\": strTitle,\n",
    "                \"link\":strUrl,\n",
    "                \"body\":strBody,\n",
    "                \"postdate\":strDate,\n",
    "                #\"updatetime\":datetime.datetime.now(),  # MongoDB\n",
    "                \"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "                })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    items = []\n",
    "    start_requests();\n",
    "    row_json = json.dumps(items, ensure_ascii=False)\n",
    "    file = codecs.open(urllib.parse.unquote(keyword)+'.json', 'w', encoding='utf-8')\n",
    "    #file = codecs.open('out.json', 'w', encoding='utf-8')\n",
    "    file.write(row_json)\n",
    "    file.close()\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
