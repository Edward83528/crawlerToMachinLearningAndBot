{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urllib - xpath - 自由時報關鍵字,內文摘要 - 輸出JSON檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.ltn.com.tw/search?keyword=%E8%82%BA%E7%82%8E&conditions=and&SYear=2020&SMonth=04&SDay=14&EYear=2020&EMonth=04&EDay=15&page=1\n",
      "range(0, 15)\n",
      "4/15重要財經新聞一覽\n",
      "https://news.ltn.com.tw/news/business/breakingnews/3134053\n",
      "媽祖誕辰人流管制 新莊慈祐宮入內參拜限500人\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3134046\n",
      "疫情重創航空業 波音3月份150架飛機訂單被取消\n",
      "https://news.ltn.com.tw/news/business/breakingnews/3134012\n",
      "可惡！網騙賣醫療口罩 他竟用仙貝零食掉包\n",
      "https://news.ltn.com.tw/news/society/breakingnews/3134034\n",
      "新台幣再見2字頭！早盤漲逾1角\n",
      "https://news.ltn.com.tw/news/business/breakingnews/3134047\n",
      "籲中央擴大紓困 侯友宜：很多補助看得到、吃不到\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3134045\n",
      "美國最快5月1日前復工！川普：將與50位州長進行談話\n",
      "https://news.ltn.com.tw/news/business/breakingnews/3134006\n",
      "小男生不敢戴粉紅色口罩 議員戴花口罩鼓勵\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3134040\n",
      "車市遇逆風 東陽首季EPS僅0.73元\n",
      "https://news.ltn.com.tw/news/business/breakingnews/3134032\n",
      "人命和經濟嚴重損失 美國務卿暗示將對中國究責\n",
      "https://news.ltn.com.tw/news/world/breakingnews/3133972\n",
      "寫信通報WHO操刀人是她！前疾管局長：一看就知代誌大條...\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3134017\n",
      "贊同停止金援世衛 川普貿易顧問矛頭指向中國\n",
      "https://news.ltn.com.tw/news/world/breakingnews/3133992\n",
      "暴買愛馬仕？傳廣州單店一天經營業額逾8000萬 震撼時尚圈\n",
      "https://news.ltn.com.tw/news/business/breakingnews/3133990\n",
      "警告中國 美軍機3週內12度在台灣周邊飛行\n",
      "https://news.ltn.com.tw/news/politics/breakingnews/3133953\n",
      "再拚零確診 陳時中今將參拜大甲媽祈求疫情穩定\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3134007\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#65001\n",
    "import urllib.request\n",
    "import json\n",
    "import codecs\n",
    "import sys\n",
    "import argparse as ap\n",
    "import time\n",
    "import datetime\n",
    "import lxml.html\n",
    "from urllib.parse import quote\n",
    "from random import randint\n",
    "\n",
    "#python main.py 世大運 2015-07-01 2017-07-03 1\n",
    "# def argParse():\n",
    "#     parser=ap.ArgumentParser(description='Liberty Time Net Crawler')\n",
    "#     parser.add_argument(\"keyword\", help=\"Serch Keyword\")\n",
    "#     parser.add_argument(\"start_date\", help=\"Start (2017-01-01)\")\n",
    "#     parser.add_argument(\"end_date\", help=\"End (2017-01-02)\")\n",
    "#     parser.add_argument(\"pages\", help=\"Pages\")\n",
    "#     return parser.parse_args()\n",
    "\n",
    "# args=argParse()\n",
    "# keyword = quote(args.keyword)\n",
    "# start_date = args.start_date\n",
    "# end_date = args.end_date\n",
    "# pages = args.pages\n",
    "\n",
    "keyword = quote('肺炎')\n",
    "start_date = '2020-04-14'\n",
    "end_date = '2020-04-15'\n",
    "pages = '1'\n",
    "\n",
    "\n",
    "def start_requests():\n",
    "    start_list = start_date.split(\"-\")\n",
    "    end_list = end_date.split(\"-\")\n",
    "    SYear = ''\n",
    "    SMonth = ''\n",
    "    SDay = ''\n",
    "    EYear = ''\n",
    "    EMonth = ''\n",
    "    EDay = ''\n",
    "    if(len(start_list)==3) and (len(end_list)==3):\n",
    "        SYear = start_list[0]\n",
    "        SMonth = start_list[1]\n",
    "        SDay = start_list[2]\n",
    "        EYear = end_list[0]\n",
    "        EMonth = end_list[1]\n",
    "        EDay = end_list[2]\n",
    "    else:\n",
    "        print (\"Date format error.\")\n",
    "  \n",
    "    urls = []\n",
    "    for i in range(1,int(pages)+1):\n",
    "        str_idx = ''+('%s' % i)\n",
    "        #http://news.ltn.com.tw/search?keyword=世大運&conditions=and&SYear=2015&SMonth=6&SDay=27&EYear=2015&EMonth=8&EDay=24&page=1\n",
    "        api = 'http://news.ltn.com.tw/search?keyword='+keyword+'&conditions=and&SYear='+SYear+'&SMonth='+SMonth+'&SDay='+SDay+'&EYear='+EYear+'&EMonth='+EMonth+'&EDay='+EDay+'&page='+str_idx+''\n",
    "        api = 'https://news.ltn.com.tw/search?keyword='+keyword+'&conditions=and&start_time='+start_date+'&end_time='+end_date+'&page='+str_idx\n",
    "        urls.append(api)\n",
    "        for url in urls:\n",
    "            #print (url)\n",
    "            parseLtnNews(url)\n",
    "            time.sleep(0.2)\n",
    "\n",
    "\n",
    "def parseLtnNews(uri):\n",
    "    print(uri)\n",
    "    handle = urllib.request.urlopen(uri)\n",
    "    encoding = handle.headers.get_content_charset()\n",
    "    html_data =  handle.read().decode(encoding)\n",
    "    selector = lxml.html.document_fromstring(html_data)\n",
    "    newslist = selector.xpath('//*[@class=\"searchlist boxTitle\"]/li')\n",
    "    print(range(len(newslist)))\n",
    "    for i in range(len(newslist)):\n",
    "        strTitle = ''\n",
    "        strUrl = ''\n",
    "        strBody = ''\n",
    "        strDate = ''\n",
    "        str_idx = str(i+1)\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/a//text()'\n",
    "        titleList = selector.xpath(str_xpath)\n",
    "        strTitle = \" \".join(titleList)\n",
    "        print(strTitle)\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/a//@href'\n",
    "        urlList = selector.xpath(str_xpath)[0]\n",
    "        strUrl = ''.join(urlList)\n",
    "        strUrl = strUrl\n",
    "        print(strUrl)\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/p//text()'\n",
    "        bodyList = selector.xpath(str_xpath)\n",
    "        strBody = ''.join(bodyList).replace('\\n','')\n",
    "        str_xpath = '//*[@class=\"searchlist boxTitle\"]/li['+str_idx+']/span//text()'\n",
    "        dateList = selector.xpath(str_xpath)\n",
    "        strDate = ''.join(dateList).replace(\"&nbsp;\",\"\")[:10]\n",
    "        if len(strTitle)>1:\n",
    "            items.append({\n",
    "                \"title\": strTitle,\n",
    "                \"link\":strUrl,\n",
    "                \"body\":strBody,\n",
    "                \"postdate\":strDate,\n",
    "                #\"updatetime\":datetime.datetime.now(),  # MongoDB\n",
    "                \"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "                })\n",
    "    handle.close()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    items = []\n",
    "    start_requests()\n",
    "    row_json = json.dumps(items, ensure_ascii=False)\n",
    "    file = codecs.open(urllib.parse.unquote(keyword)+'.json', 'w', encoding='utf-8')\n",
    "    #file = codecs.open('out.json', 'w', encoding='utf-8')\n",
    "    file.write(row_json)\n",
    "    file.close()\n",
    "\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
