{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urllib - split - 自由時報關鍵字,內文全文 - 輸出JSON檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 這是失敗的案例 版型不一 ,split不是好辦法所以用lab10解決"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.ltn.com.tw/search?keyword=%E8%82%BA%E7%82%8E&conditions=and&SYear=2020&SMonth=04&SDay=14&EYear=2020&EMonth=04&EDay=15&page=1\n",
      "未戴口罩險錯過手術  氣質女孩醫院前神救援暖翻網友\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217779\n",
      "2020-07-04\n",
      "NBA》抗疫復賽先買房壓壓驚！詹皇洛城第3座豪宅市價近12億\n",
      "https://news.ltn.com.tw/news/sports/breakingnews/3217929\n",
      "2020-07-04\n",
      "指考國文》考題超應景 全中教：閱讀不能再侷限於課內教材\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217914\n",
      "2020-07-04\n",
      "酒醉男拒戴口罩猛飄三字經大鬧高鐵 網友怒「可以拒載嗎？」\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217856\n",
      "2020-07-04\n",
      "無懼過度炒作警告  韓生技公司上市連2天狂漲30％\n",
      "https://news.ltn.com.tw/news/business/breakingnews/3217844\n",
      "2020-07-04\n",
      "國5南下車多壅塞 高公局：暑假週六車潮估下午4、5點後紓解\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217901\n",
      "2020-07-04\n",
      "防疫比選舉累 陳其邁：疫情若未控制可能不會返鄉選市長\n",
      "https://news.ltn.com.tw/news/politics/breakingnews/3217896\n",
      "2020-07-04\n",
      "提前為虎爺慶生 台南祀典興濟宮募資買炸雞\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217899\n",
      "2020-07-04\n",
      "指考國文》紅樓夢、笛卡兒、尼采均入題 補教師：很多爆難題\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217893\n",
      "2020-07-04\n",
      "紙風車劇團浴火重生 國家「口罩隊」變身「藝文隊」相助\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217887\n",
      "2020-07-04\n",
      "武漢肺炎》請鬼拿藥單？巴西批准中國疫苗進行臨床試驗\n",
      "https://news.ltn.com.tw/news/world/breakingnews/3217861\n",
      "2020-07-04\n",
      "越南擬將台灣列入優先解封名單 陳時中透露：就快了\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217864\n",
      "2020-07-04\n",
      "指考國文》近3年最難！6成文言文 古今對照談疾疫照護\n",
      "https://news.ltn.com.tw/news/life/breakingnews/3217848\n",
      "2020-07-04\n",
      "MLB》三位至親確診武肺 響尾蛇終結者嚴陣以待\n",
      "https://news.ltn.com.tw/news/sports/breakingnews/3217726\n",
      "2020-07-04\n",
      "土耳其工廠逾百噸滯銷煙火爆炸 增至4死108傷3失蹤\n",
      "https://news.ltn.com.tw/news/world/breakingnews/3217704\n",
      "2020-07-04\n",
      "© 2020 The\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#65001\n",
    "import urllib.request\n",
    "import json\n",
    "import codecs\n",
    "import sys\n",
    "import argparse as ap\n",
    "import time\n",
    "import datetime\n",
    "from urllib.parse import quote\n",
    "\n",
    "# def argParse():\n",
    "#     parser=ap.ArgumentParser(description='Liberty Time Net Crawler')\n",
    "#     parser.add_argument(\"keyword\", help=\"Serch Keyword\")\n",
    "#     parser.add_argument(\"start_date\", help=\"Start (2017-01-01)\")\n",
    "#     parser.add_argument(\"end_date\", help=\"End (2017-01-02)\")\n",
    "#     parser.add_argument(\"pages\", help=\"Pages\")\n",
    "#     return parser.parse_args()\n",
    "\n",
    "# args=argParse()\n",
    "# keyword = quote(args.keyword)\n",
    "# start_date = args.start_date\n",
    "# end_date = args.end_date\n",
    "# pages = args.pages\n",
    "\n",
    "keyword = quote('肺炎')\n",
    "start_date = '2020-04-14'\n",
    "end_date = '2020-04-15'\n",
    "pages = '1'\n",
    "\n",
    "def request_uri(uri):\n",
    "    handle = urllib.request.urlopen(uri)\n",
    "    encoding = handle.headers.get_content_charset()\n",
    "    html_data =  handle.read().decode(encoding)\n",
    "    return html_data\n",
    "\n",
    "def strip_tags(html_data):\n",
    "    tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')\n",
    "    no_tags = tag_re.sub('', html_data)\n",
    "    return re.sub('<[^<]+?>', '', html_data)\n",
    "\n",
    "def start_requests():\n",
    "    start_list = start_date.split(\"-\")\n",
    "    end_list = end_date.split(\"-\")\n",
    "    SYear = ''\n",
    "    SMonth = ''\n",
    "    SDay = ''\n",
    "    EYear = ''\n",
    "    EMonth = ''\n",
    "    EDay = ''\n",
    "    if(len(start_list)==3) and (len(end_list)==3):\n",
    "        SYear = start_list[0]\n",
    "        SMonth = start_list[1]\n",
    "        SDay = start_list[2]\n",
    "        EYear = end_list[0]\n",
    "        EMonth = end_list[1]\n",
    "        EDay = end_list[2]\n",
    "    else:\n",
    "        print (\"Date format error.\")\n",
    "  \n",
    "    urls = []\n",
    "    for i in range(1,int(pages)+1):\n",
    "        str_idx = ''+('%s' % i)\n",
    "        #http://news.ltn.com.tw/search?keyword=蘋果&conditions=and&SYear=2018&SMonth=03&SDay=01&EYear=2018&EMonth=03&EDay=05&page=1\n",
    "        api = 'http://news.ltn.com.tw/search?keyword='+keyword+'&conditions=and&SYear='+SYear+'&SMonth='+SMonth+'&SDay='+SDay+'&EYear='+EYear+'&EMonth='+EMonth+'&EDay='+EDay+'&page='+str_idx+''\n",
    "        urls.append(api)\n",
    "        print('http://news.ltn.com.tw/search?keyword='+keyword+'&conditions=and&SYear='+SYear+'&SMonth='+SMonth+'&SDay='+SDay+'&EYear='+EYear+'&EMonth='+EMonth+'&EDay='+EDay+'&page='+str_idx+'')\n",
    "        for url in urls:\n",
    "            #print (url)\n",
    "            parseLtnNews(url)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "\n",
    "def parseLtnNews(uri):\n",
    "    handle = urllib.request.urlopen(uri)\n",
    "    encoding = handle.headers.get_content_charset()\n",
    "    html_data =  handle.read().decode(encoding)\n",
    "    aryTemp01 = html_data.split('class=\"searchlist boxTitle\"')\n",
    "    if len(aryTemp01)>1:\n",
    "        for a in aryTemp01[1].split('<li>'):\n",
    "            title = ''\n",
    "            link = ''\n",
    "            body = ''\n",
    "            postdate = ''\n",
    "            aryTemp02 = a.split('<p>')\n",
    "            if len(aryTemp02)>1:\n",
    "                body = aryTemp02[1].split('</p>')[0].replace(\"\\n\",\"\").replace(\"<strong>\",\"\").replace(\"</strong>\",\"\")\n",
    "                #print(body)\n",
    "            aryTemp02 = a.split('class=\"tit\" href=\"')\n",
    "            if len(aryTemp02)>1:\n",
    "                title = aryTemp02[1].split('\">')[1].split(\"</a>\")[0].replace(\"\\n\",\"\").replace(\"<strong>\",\"\").replace(\"</strong>\",\"\")\n",
    "                print(title)\n",
    "                aryTemp03 = aryTemp02[1].split('\"')\n",
    "                link = aryTemp03[0]\n",
    "                print(link)\n",
    "                html_data2 = request_uri(link)\n",
    "                if 'data-desc=\"內文\">' in html_data2:\n",
    "                        aryTemp02 = html_data2.split('data-desc=\"內文\">')\n",
    "                        aryTemp03 = aryTemp02[1].split('</span>')\n",
    "                        if len(aryTemp03)>1:\n",
    "                            aryTemp04 = aryTemp03[1].split('<ul class=\"pic300')\n",
    "                            #print(aryTemp04[0])\n",
    "                            if len(aryTemp04)>1:\n",
    "                                body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                body = ''.join(body.split('<p>'))\n",
    "                                body = ''.join(body.split('</p>'))\n",
    "                                body = ''.join(body.split('</b>'))\n",
    "                            elif 'oneadIRTag' in aryTemp03[1]:\n",
    "                                aryTemp04 = aryTemp03[1].split('<div id')\n",
    "                                if len(aryTemp04)>1:\n",
    "                                    body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                    body = ''.join(body.split('<p>'))\n",
    "                                    body = ''.join(body.split('</p>'))\n",
    "                                    body = ''.join(body.split('</b>'))\n",
    "                                \n",
    "                if(len(body)==0):\n",
    "                    aryTemp02 = html_data2.split('articleBody\">')\n",
    "                    if len(aryTemp02)>2:\n",
    "                        aryTemp03 = aryTemp02[2].split('class=\"ph_d\">')\n",
    "                        if len(aryTemp03)>1:\n",
    "                            aryTemp04 = aryTemp03[1].split('</div>')\n",
    "                            if len(aryTemp04)>1:\n",
    "                                body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                body = ''.join(body.split('<p>'))\n",
    "                                body = ''.join(body.split('</p>'))\n",
    "                                body = ''.join(body.split('</b>'))\n",
    "                                if '<table' in body:\n",
    "                                    body = body.split('<table')[0]\n",
    "                                body = body.replace('</span>','').replace('<span>','')\n",
    "                                #print(body)\n",
    "                            else:\n",
    "                                #<p><span class=\"ph_b ph_d1\">\n",
    "                                aryTemp04 = aryTemp03[1].split('<p><span class=\"ph_b ph_d1\">')\n",
    "                                if len(aryTemp04)>1:\n",
    "                                    body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                    body = ''.join(body.split('<p>'))\n",
    "                                    body = ''.join(body.split('</p>'))\n",
    "                                    body = ''.join(body.split('</b>'))\n",
    "                                    if '<table' in body:\n",
    "                                        body = body.split('<table')[0]\n",
    "                                        body = body.replace('</span>','').replace('<span>','')\n",
    "                        else:\n",
    "                            aryTemp04 = aryTemp02[1].split('</div>')\n",
    "                            if len(aryTemp04)>1:\n",
    "                                body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                body = ''.join(body.split('<p>'))\n",
    "                                body = ''.join(body.split('</p>'))\n",
    "                                body = ''.join(body.split('</b>'))\n",
    "                                if '<table' in body:\n",
    "                                    body = body.split('<table')[0]\n",
    "                                body = body.replace('</span>','').replace('<span>','')\n",
    "                    elif len(aryTemp02)>1:\n",
    "                        if \"class='ph_d'\" in aryTemp02[1]:\n",
    "                            aryTemp03 = aryTemp02[1].split(\"class='ph_d'>\")\n",
    "                        elif 'class=\"ph_d\"' in aryTemp02[1]:\n",
    "                            aryTemp03 = aryTemp02[1].split('class=\"ph_d\">')\n",
    "                        if len(aryTemp03)>1:\n",
    "                            aryTemp04 = aryTemp03[1].split('</div>')\n",
    "                            if len(aryTemp04)>1:\n",
    "                                body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                body = ''.join(body.split('<p>'))\n",
    "                                body = ''.join(body.split('</p>'))\n",
    "                                body = ''.join(body.split('</b>'))\n",
    "                                if '<table' in body:\n",
    "                                    body = body.split('<table')[0]\n",
    "                                body = body.replace('</span>','').replace('<span>','')\n",
    "                                #print(body)\n",
    "                            else:\n",
    "                                #<p><span class=\"ph_b ph_d1\">\n",
    "                                aryTemp04 = aryTemp03[1].split('<p><span class=\"ph_b ph_d1\">')\n",
    "                                if len(aryTemp04)>1:\n",
    "                                    body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                    body = ''.join(body.split('<p>'))\n",
    "                                    body = ''.join(body.split('</p>'))\n",
    "                                    body = ''.join(body.split('</b>'))\n",
    "                                    if '<table' in body:\n",
    "                                        body = body.split('<table')[0]\n",
    "                                        body = body.replace('</span>','').replace('<span>','')\n",
    "                        else:\n",
    "                            aryTemp04 = aryTemp02[1].split('</div>')\n",
    "                            if len(aryTemp04)>1:\n",
    "                                body = ''.join(aryTemp04[0].split('\\n'))\n",
    "                                body = ''.join(body.split('<p>'))\n",
    "                                body = ''.join(body.split('</p>'))\n",
    "                                body = ''.join(body.split('</b>'))\n",
    "                                if '<table' in body:\n",
    "                                    body = body.split('<table')[0]\n",
    "                                body = body.replace('</span>','').replace('<span>','')\n",
    "                                #print(body)\n",
    "                body = body.split('<iframe')[0]\n",
    "                body = body.split('<script>')[0]\n",
    "                if(str(body)==''):\n",
    "                    #re.sub('<[^<]+?>', '', text)\n",
    "                    tmpBody = []\n",
    "                    aryTemp02 = html_data2.split('articleBody\">')\n",
    "                    if len(aryTemp02)>1:\n",
    "                        aryTemp03 = aryTemp02[1].split(\"<span class='ph_b'>\")\n",
    "                        if len(aryTemp03)>1:\n",
    "                            for x in aryTemp03[1:]:\n",
    "                                if 'div-inread-ad' in x:\n",
    "                                    tmpBody.append(strip_tags(x.split('<div id=\"div-inread-ad\">')[0]))\n",
    "                                else:\n",
    "                                    tmpBody.append(strip_tags(x))\n",
    "                            body = ' '.join(tmpBody)\n",
    "                    if(str(body)==''):\n",
    "                        print(link)\n",
    "            aryTemp02 = a.split('<span>')\n",
    "            if len(aryTemp02)>1:\n",
    "                postdate = aryTemp02[1].split('</span>')[0].replace(\"&nbsp;\",\"\")[:10]\n",
    "                print(postdate)\n",
    "            if len(title)>1:\n",
    "                items.append({\n",
    "                    \"title\": title,\n",
    "                    \"link\":link,\n",
    "                    \"body\":body,\n",
    "                    \"postdate\":postdate,\n",
    "                    #\"updatetime\":datetime.datetime.now(),  # MongoDB\n",
    "                    \"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "                    })\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    items = []\n",
    "    start_requests();\n",
    "    row_json = json.dumps(items, ensure_ascii=False)\n",
    "    file = codecs.open(urllib.parse.unquote(keyword)+'.json', 'w', encoding='utf-8')\n",
    "    #file = codecs.open('out.json', 'w', encoding='utf-8')\n",
    "    file.write(row_json)\n",
    "    file.close()\n",
    "    #print(row_json)\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
