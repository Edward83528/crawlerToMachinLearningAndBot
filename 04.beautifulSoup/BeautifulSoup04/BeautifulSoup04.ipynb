{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用 BeautifulSoup 拆解法 - 蘋果日報關鍵字查詢為例 - 摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tw.news.appledaily.com/search/, page=1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#65001\n",
    "import urllib.request\n",
    "import json\n",
    "import codecs\n",
    "import sys\n",
    "import argparse as ap\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote\n",
    "\n",
    "#python main.py 八仙塵爆 2015-06-27 2015-08-24 1\n",
    "#def argParse():\n",
    "#    parser=ap.ArgumentParser(description='Apple Daily News Crawler')\n",
    "#    parser.add_argument(\"keyword\", help=\"Serch Keyword\")\n",
    "#    parser.add_argument(\"start_date\", help=\"Start (2017-01-01)\")\n",
    "#    parser.add_argument(\"end_date\", help=\"End (2017-02-02)\" )\n",
    "#    parser.add_argument(\"pages\", help=\"Pages\")\n",
    "#    return parser.parse_args()\n",
    "\n",
    "#args=argParse()\n",
    "#keyword = args.keyword\n",
    "#start_date = args.start_date\n",
    "#end_date = args.end_date\n",
    "#pages = args.pages\n",
    "\n",
    "keyword = '川普'\n",
    "start_date = '2018-03-02'\n",
    "end_date = '2018-03-05'\n",
    "pages = '1'\n",
    "\n",
    "rs = requests.session()\n",
    "\n",
    "def start_requests(uri):\n",
    "    if( len(start_date.split(\"-\"))==3 and len(end_date.split(\"-\"))==3) :\n",
    "        for i in range(1,int(pages)+1):\n",
    "            str_page = ''+('%s' % i)\n",
    "            str_rand = str(random.randint(1,99999))\n",
    "            print (uri+\", page=\"+str_page)\n",
    "            parseLtnNews(uri,str_page)\n",
    "            time.sleep(0.5)\n",
    "      \n",
    "    else:\n",
    "        print (\"Data format error.\")\n",
    "\n",
    "\n",
    "def request_uri(uri,str_page):\n",
    "    #header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0','Content-Type': 'application/x-www-form-urlencoded', 'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8','Accept-Encoding':'gzip, deflate','Referer':'http://search.appledaily.com.tw/appledaily/search'}\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0'}\n",
    "    #searchMode:Adv\n",
    "    #searchType:text\n",
    "    #querystrA:蘋果\n",
    "    #select:AND\n",
    "    #source:\n",
    "    #sdate:2018-03-02\n",
    "    #edate:2018-03-05\n",
    "    data = {\"searchMode\":\"Adv\",\"searchType\":\"text\",\"querystrA\":keyword,\"select\":\"AND\",\"source\":\"\",\"sdate\":start_date,\"edate\":end_date,\"sorttype\":\"1\",\"page\":str_page}\n",
    "    res = rs.post(uri, data=data, headers=header)\n",
    "    html_data =  res.text\n",
    "    return html_data\n",
    "\n",
    "                        \n",
    "def request_uri_content(uri):\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0'}\n",
    "    res = rs.get(uri, headers=header)\n",
    "    html_data =  res.text\n",
    "    return html_data\n",
    "\n",
    "                        \n",
    "def parseLtnNews(uri,str_page):\n",
    "    html_data =  request_uri(uri,str_page)\n",
    "    soup = bs(html_data,'html.parser')\n",
    "    \n",
    "    postdate = []\n",
    "    link = []\n",
    "    title = []\n",
    "    body = []\n",
    "    for div_soup in soup.findAll('div',attrs={\"class\":\"tbb\"}):\n",
    "        #items.append({\"uri\":uri+'&page='+str_page,\"div_soup\":str(div_soup),\"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')})\n",
    "        for a_soup in div_soup.findAll('h2'):\n",
    "            title.append(a_soup.text)\n",
    "        for p_soup in div_soup.findAll('p'):\n",
    "            body.append(p_soup.text)\n",
    "        for li_soup in div_soup.findAll('li'):\n",
    "            for a_soup in li_soup.findAll('a'):\n",
    "                content_uri = a_soup.get('href').strip()\n",
    "                #body.append(p_soup2.getText().replace('有話要說 投稿「即時論壇」','').strip())\n",
    "                link.append(content_uri)\n",
    "\n",
    "    for time_soup in soup.findAll('time'):\n",
    "        tmp_d = ''\n",
    "        if len(time_soup.getText())==8:\n",
    "            tmp_d = time_soup.getText()[0:4]+'-'+time_soup.getText()[4:6]+'-'+time_soup.getText()[6:8]\n",
    "        #elif len(time_soup.getText())==5:\n",
    "            #tmp_d = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "        if len(tmp_d)>1:\n",
    "            postdate.append(tmp_d)\n",
    "        \n",
    "    \n",
    "    current = 0\n",
    "    while current < len(postdate):\n",
    "        items.append({\n",
    "          \"title\": title[current],\n",
    "          \"link\":link[current],\n",
    "          \"body\":body[current],\n",
    "          \"postdate\":postdate[current],\n",
    "          #\"updatetime\":datetime.datetime.now(),  # MongoDB\n",
    "          \"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "        })\n",
    "        current+=1\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #uri = 'http://search.appledaily.com.tw/appledaily/search'\n",
    "    uri = 'https://tw.news.appledaily.com/search/'\n",
    "    items = []\n",
    "    start_requests(uri);\n",
    "    row_json = json.dumps(items, ensure_ascii=False)\n",
    "    file = codecs.open(urllib.parse.unquote(keyword)+'.json', 'w', encoding='utf-8')\n",
    "    file.write(row_json)\n",
    "    file.close()\n",
    "    r = requests.get(url=uri, headers={'Connection':'close'})\n",
    "\n",
    "    print(\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
