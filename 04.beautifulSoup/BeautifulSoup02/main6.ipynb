{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.ltn.com.tw/search?keyword=%E4%B8%96%E5%A4%A7%E9%81%8B&conditions=and&SYear=2017&SMonth=07&SDay=01&EYear=2017&EMonth=07&EDay=15&page=1\n",
      "\n",
      "怒批泳協回應前後矛盾 體改聯會提出多項質疑\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2133255\n",
      "\n",
      "瓊斯盃》周儀翔豪取22分 台灣藍射日奪首勝\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2133220\n",
      "\n",
      "瓊斯盃》和平球場暗藏危機 資深裁判先掛彩\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2133162\n",
      "\n",
      "北捷世大運彩繪列車登知名網站 外國網友大讚\n",
      "\n",
      "http://news.ltn.com.twnews/life/breakingnews/2132968\n",
      "\n",
      "柯P開金口唱老歌 「不記恨」蘇打綠挑戰小巨蛋阿妹條款\n",
      "\n",
      "http://news.ltn.com.twnews/life/breakingnews/2132940\n",
      "\n",
      "世大運聖火到金門 盼溫度「暖」到廈門\n",
      "\n",
      "http://news.ltn.com.twnews/life/breakingnews/2132918\n",
      "\n",
      "柯文哲想「把他宰了」 王國材：咬人也要咬對對象\n",
      "\n",
      "http://news.ltn.com.twnews/politics/breakingnews/2132943\n",
      "\n",
      "柯文哲個人IG上線 目標：寫字不超過一句話\n",
      "\n",
      "http://news.ltn.com.twnews/politics/breakingnews/2132893\n",
      "\n",
      "中國已報名世大運個人賽？ 柯P：本來就一定會來\n",
      "\n",
      "http://news.ltn.com.twnews/life/breakingnews/2132900\n",
      "\n",
      "瓊斯盃》陳盈駿殺翻天 白隊3分惜敗南韓\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2132844\n",
      "\n",
      "瓊斯盃》和平籃球館模擬世大運安檢 球迷不覺得麻煩\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2132806\n",
      "\n",
      "泳后控協會黑箱  世大運教練回應：「女將無人達標」\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2132794\n",
      "\n",
      "世大運》拜師桌球王子江宏傑 Duncan：想娶可愛老婆\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2132786\n",
      "\n",
      "世大運》Duncan與江宏傑PK桌球 竟用一句話完勝？（影音）\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2132776\n",
      "\n",
      "全大運金牌卻不能參加世大運？「泳后」控協會黑箱\n",
      "\n",
      "http://news.ltn.com.twnews/sports/breakingnews/2132495\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#65001\n",
    "import urllib.request\n",
    "import json\n",
    "import codecs\n",
    "import sys\n",
    "import argparse as ap\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote\n",
    "\n",
    "#python main.py 八仙塵爆 2015-06-27 2015-08-24 1\n",
    "#def argParse():\n",
    "#    parser=ap.ArgumentParser(description='Liberty Time Net Crawler')\n",
    "#    parser.add_argument(\"keyword\", help=\"Serch Keyword\")\n",
    "#    parser.add_argument(\"start_date\", help=\"Start (2017-01-01)\")\n",
    "#    parser.add_argument(\"end_date\", help=\"End (2017-01-02)\")\n",
    "#    parser.add_argument(\"pages\", help=\"Pages\")\n",
    "#    return parser.parse_args()\n",
    "\n",
    "#args=argParse()\n",
    "#keyword = quote(args.keyword)\n",
    "#start_date = args.start_date\n",
    "#end_date = args.end_date\n",
    "#pages = args.pages\n",
    "\n",
    "keyword = quote('世大運')\n",
    "start_date = '2017-07-01'\n",
    "end_date = '2017-07-15'\n",
    "pages = '1'\n",
    "\n",
    "def start_requests():\n",
    "    if( len(start_date.split(\"-\"))==3 and len(end_date.split(\"-\"))==3) :\n",
    "        SYear = start_date.split(\"-\")[0]\n",
    "        SMonth = start_date.split(\"-\")[1]\n",
    "        SDay = start_date.split(\"-\")[2]\n",
    "        EYear = end_date.split(\"-\")[0]\n",
    "        EMonth = end_date.split(\"-\")[1]\n",
    "        EDay = end_date.split(\"-\")[2]\n",
    "        urls = []\n",
    "        for i in range(1,int(pages)+1):\n",
    "            str_idx = ''+('%s' % i)\n",
    "            urls.append('http://news.ltn.com.tw/search?keyword='+keyword+'&conditions=and&SYear='+SYear+'&SMonth='+SMonth+'&SDay='+SDay+'&EYear='+EYear+'&EMonth='+EMonth+'&EDay='+EDay+'&page='+str_idx+'')\n",
    "\n",
    "        for url in urls:\n",
    "            print (url)\n",
    "            parseLtnNews(url)\n",
    "            time.sleep(0.5)\n",
    "    else:\n",
    "        print (\"Data format error.\")\n",
    "\n",
    "        \n",
    "def request_uri(uri):\n",
    "    header = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "    rs = requests.session()\n",
    "    res = rs.get(uri, headers=header)\n",
    "    html_data =  res.text\n",
    "    #r = requests.post(url=uri, headers={'Connection':'close'})\n",
    "    return html_data\n",
    "\n",
    "\n",
    "def parseLtnNews(uri):\n",
    "    postdate = []\n",
    "    link = []\n",
    "    title = []\n",
    "    body = []\n",
    "    html_data =  request_uri(uri)\n",
    "    soup = bs(html_data,'html.parser')\n",
    "    for ul_soup in soup.findAll('ul',attrs={\"id\":\"newslistul\"}):\n",
    "        for span_soup in ul_soup.findAll('span'):\n",
    "            postdate = span_soup.string.replace(\"&nbsp;\",\"\")[:10]\n",
    "        for li_soup in ul_soup.findAll('li'):\n",
    "            p_list = li_soup.findAll('p')\n",
    "            body=p_list[1].getText()\n",
    "            items.append({\"uri\":uri,\"body\":body,\"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')})\n",
    "            #print({\"uri\":uri,\"body\":body,\"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')})\n",
    "        for a_soup in ul_soup.findAll('a',attrs={\"class\":\"tit\"}):\n",
    "            tle = a_soup.getText()\n",
    "            lnk = 'http://news.ltn.com.tw'+a_soup.get('href')\n",
    "            title.append(tle.strip())\n",
    "            link.append(lnk)\n",
    "            print(tle)\n",
    "            print(lnk)\n",
    "        #TO DO\n",
    "\n",
    "    current = 0\n",
    "    while current < len(postdate):\n",
    "        items.append({\n",
    "                \"title\": title[current],\n",
    "                \"link\":link[current],\n",
    "                \"body\":body[current],\n",
    "                \"postdate\":postdate[current],\n",
    "                #\"updatetime\":datetime.datetime.now(),  # MongoDB\n",
    "                \"updatetime\":datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "            })\n",
    "        current+=1\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    items = []\n",
    "    start_requests();\n",
    "    row_json = json.dumps(items, ensure_ascii=False)\n",
    "    file = codecs.open(urllib.parse.unquote(keyword)+'.json', 'w', encoding='utf-8')\n",
    "    file.write(row_json)\n",
    "    file.close()\n",
    "  \n",
    "\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
